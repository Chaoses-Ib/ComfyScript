{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comfy_script.runtime import *\n",
    "\n",
    "# load('http://127.0.0.1:8188/')\n",
    "load()\n",
    "\n",
    "# Nodes can only be imported after load()\n",
    "from comfy_script.runtime.nodes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Workflow():\n",
    "    seed = 0\n",
    "    pos = 'sky, 1girl, smile'\n",
    "    neg = 'embedding:easynegative'\n",
    "    model, clip, vae = CheckpointLoaderSimple(Checkpoints.AOM3A1B_orangemixs)\n",
    "    model2, clip2, vae2 = CheckpointLoaderSimple(Checkpoints.CounterfeitV25_25)\n",
    "    model2 = TomePatchModel(model2, 0.5)\n",
    "    for color in 'red', 'green', 'blue':\n",
    "        latent = EmptyLatentImage(440, 640)\n",
    "        latent = KSampler(model, seed, steps=15, cfg=6, sampler_name='uni_pc',\n",
    "                          positive=CLIPTextEncode(f'{color}, {pos}', clip), negative=CLIPTextEncode(neg, clip),\n",
    "                          latent_image=latent)\n",
    "        SaveImage(VAEDecode(latent, vae2), f'{seed} {color}')\n",
    "        latent = LatentUpscaleBy(latent, scale_by=2)\n",
    "        latent = KSampler(model2, seed, steps=15, cfg=6, sampler_name='uni_pc',\n",
    "                          positive=CLIPTextEncode(f'{color}, {pos}', clip2), negative=CLIPTextEncode(neg, clip2),\n",
    "                          latent_image=latent, denoise=0.6)\n",
    "        SaveImage(VAEDecode(latent, vae2), f'{seed} {color} hires')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
